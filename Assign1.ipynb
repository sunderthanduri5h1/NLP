{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assign1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgwCHpb-oKOk"
      },
      "source": [
        "Passage \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkOIHrRSoERz"
      },
      "source": [
        "Are  you  fascinated  by  the  amount  of  text  data  available  on  the  internet?  Are  you \n",
        "looking  for  ways  to  work  with  this  text  data  but  aren’t  sure  where  to  begin? \n",
        "Machines, after all, recognize numbers, not the letters of our language. And that can \n",
        "be a tricky landscape to navigate in machine learning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSvElgIRpDEB",
        "outputId": "80092bfb-c8b6-4351-dd6c-09f36bfd556a"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoJU053VojbU"
      },
      "source": [
        "t=\"Are you fascinated by the amount of text data available on the internet? Are you looking for ways to work with this text data but aren’t sure where to begin? Machines, after all, recognize numbers, not the letters of our language. And that can be a tricky landscape to navigate in machine learning.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UZqJAjroRLI"
      },
      "source": [
        "1. Split the above paragraph into sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R57Gy9GsoIfw"
      },
      "source": [
        "from nltk.tokenize import sent_tokenize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wVdVwDeoIwm",
        "outputId": "fe7063d5-df8c-43e8-cec2-bbabdda16c4f"
      },
      "source": [
        "print(sent_tokenize(t),end=\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Are you fascinated by the amount of text data available on the internet?', 'Are you looking for ways to work with this text data but aren’t sure where to begin?', 'Machines, after all, recognize numbers, not the letters of our language.', 'And that can be a tricky landscape to navigate in machine learning.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeKKa_hzpPsE"
      },
      "source": [
        "2.Split the above paragraph into words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fUzJ694pWcH"
      },
      "source": [
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nIDleh1pddJ",
        "outputId": "3ffeaab6-15eb-41ce-cd62-93b7f09e1a21"
      },
      "source": [
        "words=word_tokenize(t)\n",
        "#print(len(words))\n",
        "print(words)\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Are', 'you', 'fascinated', 'by', 'the', 'amount', 'of', 'text', 'data', 'available', 'on', 'the', 'internet', '?', 'Are', 'you', 'looking', 'for', 'ways', 'to', 'work', 'with', 'this', 'text', 'data', 'but', 'aren', '’', 't', 'sure', 'where', 'to', 'begin', '?', 'Machines', ',', 'after', 'all', ',', 'recognize', 'numbers', ',', 'not', 'the', 'letters', 'of', 'our', 'language', '.', 'And', 'that', 'can', 'be', 'a', 'tricky', 'landscape', 'to', 'navigate', 'in', 'machine', 'learning', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRCYBE97po7I"
      },
      "source": [
        "3.Find stem and lemma words for the given words?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbxQCsdbpsqa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a19d0926-5c8b-4d37-cb21-920aaba0b492"
      },
      "source": [
        "#stemming \n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "ps = PorterStemmer()\n",
        "word = [\"cats\",\"trouble\",\"troubling\",\"troubled\",\"having\",\"Corriendo\",\"at\",\"was\"]\n",
        "\n",
        "for w in word:\n",
        "\tprint(w, \" : \", ps.stem(w))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cats  :  cat\n",
            "trouble  :  troubl\n",
            "troubling  :  troubl\n",
            "troubled  :  troubl\n",
            "having  :  have\n",
            "Corriendo  :  corriendo\n",
            "at  :  at\n",
            "was  :  wa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4IgtqyHTDxp",
        "outputId": "0919356d-d3a7-4c7a-aa82-81ac637f2c2b"
      },
      "source": [
        "#lemmatization\n",
        "w=[\"cats\",\"trouble\",\"troubling\",\"troubled\",\"having\",\"Corriendo\",\"at\",\"was\"]\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "for i in w:\n",
        "  print(i,\"=\",lemmatizer.lemmatize(i))\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cats = cat\n",
            "trouble = trouble\n",
            "troubling = troubling\n",
            "troubled = troubled\n",
            "having = having\n",
            "Corriendo = Corriendo\n",
            "at = at\n",
            "was = wa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_JzRdxGqgrK"
      },
      "source": [
        "4.Find stop words from the given paragraph?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otIwivY5QWoQ",
        "outputId": "27c66655-e190-4df4-d80b-f4f68d1cab39"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "words = t.lower().split()\n",
        "stops = set(stopwords.words(\"english\"))\n",
        "\n",
        "words= [w for w in words if not w in stops]\n",
        "\n",
        "print(words)\n",
        "\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['fascinated', 'amount', 'text', 'data', 'available', 'internet?', 'looking', 'ways', 'work', 'text', 'data', 'aren’t', 'sure', 'begin?', 'machines,', 'all,', 'recognize', 'numbers,', 'letters', 'language.', 'tricky', 'landscape', 'navigate', 'machine', 'learning.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glCl-F-kRvtw",
        "outputId": "f2d24233-ea71-4684-fb34-8780ae35968a"
      },
      "source": [
        "print(len(words))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7m_pa7nQXih"
      },
      "source": [
        "5. From the above paragraph print frequency of each word using NLTK?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTiwzNf7qnnT",
        "outputId": "e784b7ba-4954-46ae-b066-edc2be2a5ed8"
      },
      "source": [
        "import nltk\n",
        "fdist = nltk.FreqDist(words)\n",
        "for word, freq in fdist.most_common(25):\n",
        "      print(u'{} = {}'.format(word, frequency))\n",
        "    \n",
        "\n",
        "\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text = 1\n",
            "data = 1\n",
            "fascinated = 1\n",
            "amount = 1\n",
            "available = 1\n",
            "internet? = 1\n",
            "looking = 1\n",
            "ways = 1\n",
            "work = 1\n",
            "aren’t = 1\n",
            "sure = 1\n",
            "begin? = 1\n",
            "machines, = 1\n",
            "all, = 1\n",
            "recognize = 1\n",
            "numbers, = 1\n",
            "letters = 1\n",
            "language. = 1\n",
            "tricky = 1\n",
            "landscape = 1\n",
            "navigate = 1\n",
            "machine = 1\n",
            "learning. = 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tl2bo6P3rCsU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}